# src/embedding/fused_encoder.py

# -*- coding: utf-8 -*-
"""fused_encoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZssI8QpR2EzXie_ZoBmXPNaTBnyR89QI
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.dataloader import default_collate
from tqdm import tqdm
import numpy as np
import gc
import os
import sys

sys.path.append(os.path.abspath("src"))
from dataloader.contrastive_triplets import TERRAIN_PARQUET_PATH, TRIPLET_SAVE_PATH, KEYWORD_PATH
from embedding.terrain_encoder import TerrainEncoder

EMBED_DIM = 128
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 32
EPOCHS = 10
df = pd.read_parquet(TERRAIN_PARQUET_PATH)
triplets = torch.load(TRIPLET_SAVE_PATH)
keyword_vecs = torch.load(KEYWORD_PATH)


# === Filter None values ===
def safe_collate(batch):
    batch = [b for b in batch if b is not None]
    return default_collate(batch) if batch else None

# === Text Encoder ===
class TextEncoder(nn.Module):
    def __init__(self, keyword_vecs):
        super().__init__()
        self.keyword_vecs = keyword_vecs.to(DEVICE)
        self.proj = nn.Linear(self.keyword_vecs.shape[1], EMBED_DIM)

    def forward(self, indices):
        vecs = self.keyword_vecs[indices]
        return self.proj(vecs)

# === Geo Encoder ===
class GeoEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(2, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, EMBED_DIM)
        )

    def forward(self, coords):
        return self.mlp(coords.to(DEVICE))

# === Fused Encoder ===
class FusedEncoder(nn.Module):
    def __init__(self, keyword_vecs):
        super().__init__()
        self.text_encoder = TextEncoder(keyword_vecs)
        self.geo_encoder = GeoEncoder()
        self.terrain_encoder = TerrainEncoder()
        self.fuse = nn.Sequential(
            nn.Linear(3 * EMBED_DIM, 256),
            nn.ReLU(),
            nn.Linear(256, EMBED_DIM)
        )

    def forward(self, texts, coords, terrain):
        text_emb = self.text_encoder(texts)
        geo_emb = self.geo_encoder(coords)
        terrain_emb = self.terrain_encoder(terrain)
        return self.fuse(torch.cat([text_emb, geo_emb, terrain_emb], dim=-1))

"""### Preloaded dataset for contrastive learning"""

class TripletDataset(Dataset):
    def __init__(self, df, triplets):
        self.df = df.reset_index(drop=True)
        self.triplets = triplets

    def load_patch(self, patch_id):
        path = os.path.join("data/terrain_patches", f"{patch_id}.npy")
        patch = np.load(path, mmap_mode='r')
        return torch.tensor(patch).unsqueeze(0).float() / 1000.0

    def __getitem__(self, idx):
        a_idx, p_idx, n_idx = self.triplets[idx]

        def get_item(i):
            row = self.df.iloc[i]
            patch = self.load_patch(row["terrain_patch_id"])
            coord = torch.tensor([row["lat"], row["lon"]], dtype=torch.float32)
            return patch, i, coord

        return get_item(a_idx) + get_item(p_idx) + get_item(n_idx)

    def __len__(self):
        return len(self.triplets)

# === InfoNCE Loss ===
def info_nce(anchor, positive, negative, temperature=0.07):
    anchor = F.normalize(anchor, dim=-1)
    positive = F.normalize(positive, dim=-1)
    negative = F.normalize(negative, dim=-1)
    pos_sim = torch.exp(torch.sum(anchor * positive, dim=-1) / temperature)
    neg_sim = torch.exp(torch.sum(anchor * negative, dim=-1) / temperature)
    return -torch.log(pos_sim / (pos_sim + neg_sim)).mean()

# === Training ===
if __name__ == "__main__":
    CHECKPOINT_DIR = "checkpoints"
    os.makedirs(CHECKPOINT_DIR, exist_ok=True)

    model = FusedEncoder(keyword_vecs).to(DEVICE)
    dataset = TripletDataset(df, triplets)
    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)

    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0
        for batch in tqdm(loader, desc=f"Epoch {epoch+1}/{EPOCHS}"):
            if batch is None:
                continue
            (anchor_patch, anchor_text_idx, anchor_coord,
            pos_patch, pos_text_idx, pos_coord,
            neg_patch, neg_text_idx, neg_coord) = batch

            anchor_patch, pos_patch, neg_patch = anchor_patch.to(DEVICE), pos_patch.to(DEVICE), neg_patch.to(DEVICE)
            anchor_coord, pos_coord, neg_coord = anchor_coord.to(DEVICE), pos_coord.to(DEVICE), neg_coord.to(DEVICE)

            a = model(anchor_text_idx.long().to(DEVICE), anchor_coord, anchor_patch)
            p = model(pos_text_idx.long().to(DEVICE), pos_coord, pos_patch)
            n = model(neg_text_idx.long().to(DEVICE), neg_coord, neg_patch)

            loss = info_nce(a, p, n)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

            del anchor_patch, anchor_text_idx, anchor_coord
            del pos_patch, pos_text_idx, pos_coord
            del neg_patch, neg_text_idx, neg_coord
            del a, p, n, loss
            gc.collect()

        print(f"Epoch {epoch+1}: Loss = {total_loss / len(loader):.4f}")

        checkpoint_path = os.path.join(CHECKPOINT_DIR, f"fused_encoder_epoch_{epoch+1}.pt")
        torch.save(model.state_dict(), checkpoint_path)
        print(f"Saved checkpoint to {checkpoint_path}")

    torch.save(model.state_dict(), "fused_encoder.pt")
